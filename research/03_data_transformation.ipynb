{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa28ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62121f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML_OPS_BABBY_FULL_STACK_NEW\\\\End-to-End-wine-quality-ML-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6c3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ef27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML_OPS_BABBY_FULL_STACK_NEW\\\\End-to-End-wine-quality-ML-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3af26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86afb267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"artifacts/data_ingestion/winequality-red.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7214a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for data transformation with immutable attributes.\n",
    "    \n",
    "    This dataclass defines the required parameters for the data transformation process\n",
    "    in the wine quality prediction pipeline. The 'frozen=True' parameter ensures\n",
    "    all attributes are read-only after initialization.\n",
    "    \n",
    "    Attributes:\n",
    "        root_dir (Path): Directory where all data transformation outputs will be stored,\n",
    "                        including preprocessed datasets and serialized transformers\n",
    "        data_path (Path): Path to the validated CSV file that will be transformed,\n",
    "                         output from the data ingestion step\n",
    "    \n",
    "    Note:\n",
    "        Data transformation typically includes preprocessing steps like scaling,\n",
    "        normalization, handling missing values, and train-test splitting, which\n",
    "        prepare the data for model training.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d741a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605f5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Manages configuration for the ML pipeline components.\n",
    "    \n",
    "    This class centralizes access to all configuration parameters by reading from\n",
    "    YAML configuration files and providing component-specific configuration objects.\n",
    "    \n",
    "    Attributes:\n",
    "        config: Main configuration parameters from config.yaml\n",
    "        params: Model hyperparameters and training parameters from params.yaml\n",
    "        schema: Data schema specifications from schema.yaml\n",
    "    \n",
    "    Methods:\n",
    "        get_data_ingestion_config: Returns configuration for the data ingestion component\n",
    "        get_data_validation_config: Returns configuration for the data validation component\n",
    "        get_data_transformation_config: Returns configuration for the data transformation component\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with paths to configuration files.\n",
    "        \n",
    "        Args:\n",
    "            config_filepath: Path to the main configuration file (default: CONFIG_FILE_PATH)\n",
    "            params_filepath: Path to the parameters file (default: PARAMS_FILE_PATH)\n",
    "            schema_filepath: Path to the schema file (default: SCHEMA_FILE_PATH)\n",
    "        \n",
    "        Note:\n",
    "            Creates the root artifacts directory specified in the main configuration.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        \"\"\"\n",
    "        Prepare and return the configuration for data transformation.\n",
    "        \n",
    "        This method extracts the data transformation configuration from the config file\n",
    "        and creates a DataTransformationConfig object.\n",
    "        \n",
    "        Returns:\n",
    "            DataTransformationConfig: Configuration object with all parameters\n",
    "                                     required for the data transformation component.\n",
    "                                     \n",
    "        Note:\n",
    "            Creates the root directory for data transformation if it doesn't exist.\n",
    "        \"\"\"\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00812ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05133968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    \"\"\"\n",
    "    Handles the data transformation process for the ML pipeline.\n",
    "    \n",
    "    This class is responsible for transforming the validated data into a format\n",
    "    suitable for model training. In this implementation, the transformation is\n",
    "    limited to train-test splitting since the wine quality dataset is already\n",
    "    relatively clean.\n",
    "    \n",
    "    Attributes:\n",
    "        config (DataTransformationConfig): Configuration containing all parameters\n",
    "                                           needed for the data transformation process.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        \"\"\"\n",
    "        Initialize the DataTransformation component with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config (DataTransformationConfig): Configuration object with all required\n",
    "                                               parameters for data transformation.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    ## Note: You can add different data transformation techniques such as Scaler, PCA and all\n",
    "    #You can perform all kinds of EDA in ML cycle here before passing this data to the model\n",
    "\n",
    "    # I am only adding train_test_spliting cz this data is already cleaned up\n",
    "\n",
    "\n",
    "    def train_test_spliting(self):\n",
    "        \"\"\"\n",
    "        Splits the dataset into training and testing sets.\n",
    "        \n",
    "        This method reads the validated CSV file and splits it into train and test\n",
    "        sets using a 75/25 ratio. The split datasets are saved as separate CSV files\n",
    "        in the transformation output directory.\n",
    "        \n",
    "        Process:\n",
    "        1. Reads the validated CSV data file\n",
    "        2. Splits the data using train_test_split with default 75/25 ratio\n",
    "        3. Saves the resulting datasets as train.csv and test.csv\n",
    "        4. Logs and prints the shape of the resulting datasets\n",
    "        \n",
    "        Returns:\n",
    "            None: The method saves the split datasets to disk but doesn't return them\n",
    "            \n",
    "        Note:\n",
    "            This implementation uses the default random_state in train_test_split,\n",
    "            which means the split will be different each time the pipeline runs.\n",
    "            Consider adding a fixed random_state for reproducibility.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "\n",
    "        # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "        train, test = train_test_split(data)\n",
    "\n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"),index = False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"),index = False)\n",
    "\n",
    "        logger.info(\"Splited data into training and test sets\")\n",
    "        logger.info(train.shape)\n",
    "        logger.info(test.shape)\n",
    "\n",
    "        print(train.shape)\n",
    "        print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09630364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 10:23:08,792: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-08 10:23:08,794: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-08 10:23:08,806: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-08 10:23:08,810: INFO: common: created directory at: artifacts]\n",
      "[2025-05-08 10:23:08,812: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-05-08 10:23:08,860: INFO: 4217672154: Splited data into training and test sets]\n",
      "[2025-05-08 10:23:08,862: INFO: 4217672154: (1199, 12)]\n",
      "[2025-05-08 10:23:08,863: INFO: 4217672154: (400, 12)]\n",
      "(1199, 12)\n",
      "(400, 12)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Transformation Pipeline\n",
    "\n",
    "This script orchestrates the data transformation process by initializing the configuration,\n",
    "creating the data transformation component, and executing the train-test splitting.\n",
    "\n",
    "The pipeline follows these steps:\n",
    "1. Initialize the ConfigurationManager to load all configuration parameters\n",
    "2. Get the specific data transformation configuration\n",
    "3. Initialize the DataTransformation component with the configuration\n",
    "4. Split the data into training and testing sets and save them to separate files\n",
    "\n",
    "The entire process is wrapped in a try-except block to catch and propagate\n",
    "any exceptions that might occur during execution, ensuring proper error handling.\n",
    "\n",
    "Note:\n",
    "- This is the third stage in the ML pipeline, following data validation\n",
    "- It prepares the data for model training by splitting it into train and test sets\n",
    "- While this implementation only performs train-test splitting, the component is\n",
    "  designed to be extended with additional transformation techniques like scaling,\n",
    "  normalization, or feature engineering as needed\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Initialize configuration\n",
    "    config = ConfigurationManager()\n",
    "    \n",
    "    # Get component-specific configuration\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    \n",
    "    # Initialize data transformation component\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    \n",
    "    # Execute train-test splitting\n",
    "    data_transformation.train_test_spliting()\n",
    "    \n",
    "except Exception as e:\n",
    "    # Propagate any exceptions for handling at a higher level\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06488d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
