{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcc7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961804f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML_OPS_BABBY_FULL_STACK_NEW\\\\End-to-End-wine-quality-ML-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b4f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55f8f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML_OPS_BABBY_FULL_STACK_NEW\\\\End-to-End-wine-quality-ML-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac2f30",
   "metadata": {},
   "source": [
    "##### In data validation step, we will check whether the data which we are having all the columns or not, if some is missing, we will not start the training, we will raise the exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d489e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbfbcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"artifacts/data_ingestion/winequality-red.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38cccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8eb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    \"\"\"\n",
    "    Configuration class for data validation with immutable attributes.\n",
    "    \n",
    "    This dataclass defines the required parameters for the data validation process\n",
    "    in the wine quality prediction pipeline. The 'frozen=True' parameter ensures\n",
    "    all attributes are read-only after initialization.\n",
    "    \n",
    "    Attributes:\n",
    "        root_dir (Path): Directory where all data validation outputs will be stored\n",
    "        STATUS_FILE (str): Path to the file that will contain validation status (True/False)\n",
    "        unzip_data_dir (Path): Path to the CSV file to be validated (from data ingestion)\n",
    "        all_schema (dict): Dictionary containing the expected schema information \n",
    "                          from schema.yaml, including column data types and target column\n",
    "    \n",
    "    Note:\n",
    "        The validation process compares the actual dataset against the schema\n",
    "        defined in all_schema to ensure data consistency and quality.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2cd572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mlProject.constants import *\n",
    "from src.mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785cb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    Manages configuration for the ML pipeline components.\n",
    "    \n",
    "    This class centralizes access to all configuration parameters by reading from\n",
    "    YAML configuration files and providing component-specific configuration objects.\n",
    "    \n",
    "    Attributes:\n",
    "        config: Main configuration parameters from config.yaml\n",
    "        params: Model hyperparameters and training parameters from params.yaml\n",
    "        schema: Data schema specifications from schema.yaml\n",
    "    \n",
    "    Methods:\n",
    "        get_data_ingestion_config: Returns configuration for the data ingestion component\n",
    "        get_data_validation_config: Returns configuration for the data validation component\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "        \"\"\"\n",
    "        Initialize the ConfigurationManager with paths to configuration files.\n",
    "        \n",
    "        Args:\n",
    "            config_filepath: Path to the main configuration file (default: CONFIG_FILE_PATH)\n",
    "            params_filepath: Path to the parameters file (default: PARAMS_FILE_PATH)\n",
    "            schema_filepath: Path to the schema file (default: SCHEMA_FILE_PATH)\n",
    "        \n",
    "        Note:\n",
    "            Creates the root artifacts directory specified in the main configuration.\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        \"\"\"\n",
    "        Prepare and return the configuration for data validation.\n",
    "        \n",
    "        This method extracts the data validation configuration from the config file\n",
    "        and the column schema from the schema file, then combines them into a\n",
    "        DataValidationConfig object.\n",
    "        \n",
    "        Returns:\n",
    "            DataValidationConfig: Configuration object with all parameters\n",
    "                                 required for the data validation component.\n",
    "                                 \n",
    "        Note:\n",
    "            Creates the root directory for data validation if it doesn't exist.\n",
    "            The schema.COLUMNS is passed as all_schema to validate data types.\n",
    "        \"\"\"\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            unzip_data_dir = config.unzip_data_dir,\n",
    "            all_schema=schema,\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f79aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlProject import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e41742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValiadtion:\n",
    "    \"\"\"\n",
    "    Validates the ingested data against the expected schema.\n",
    "    \n",
    "    This class is responsible for ensuring that the dataset contains all the expected\n",
    "    columns as defined in the schema. It validates the structure of the data before\n",
    "    proceeding to further steps in the ML pipeline.\n",
    "    \n",
    "    Attributes:\n",
    "        config (DataValidationConfig): Configuration containing all parameters\n",
    "                                       needed for the data validation process.\n",
    "    \"\"\"\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        \"\"\"\n",
    "        Initialize the DataValiadtion component with configuration.\n",
    "        \n",
    "        Args:\n",
    "            config (DataValidationConfig): Configuration object with all required\n",
    "                                           parameters for data validation.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def validate_all_columns(self)-> bool:\n",
    "        \"\"\"\n",
    "        Validates that all expected columns are present in the dataset.\n",
    "        \n",
    "        This method reads the CSV file from the data ingestion step and checks\n",
    "        if all columns in the dataset match the expected columns defined in the schema.\n",
    "        \n",
    "        Process:\n",
    "        1. Reads the CSV data file\n",
    "        2. Extracts the column names from the actual dataset\n",
    "        3. Compares with the expected columns from the schema\n",
    "        4. Writes the validation status to the STATUS_FILE\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if validation passes (all expected columns are present),\n",
    "                  False otherwise\n",
    "                  \n",
    "        Raises:\n",
    "            Exception: Any error during the validation process\n",
    "            \n",
    "        Note:\n",
    "            Current implementation will mark validation as True even if there are\n",
    "            additional columns not in the schema, as long as all schema columns\n",
    "            are present in the dataset.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            \n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ed94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-08 09:58:20,684: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-08 09:58:20,688: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-08 09:58:20,695: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-08 09:58:20,698: INFO: common: created directory at: artifacts]\n",
      "[2025-05-08 09:58:20,703: INFO: common: created directory at: artifacts/data_validation]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data Validation Pipeline\n",
    "\n",
    "This script orchestrates the data validation process by initializing the configuration,\n",
    "creating the data validation component, and executing the column validation step.\n",
    "\n",
    "The pipeline follows these steps:\n",
    "1. Initialize the ConfigurationManager to load all configuration parameters\n",
    "2. Get the specific data validation configuration and schema\n",
    "3. Initialize the DataValiadtion component with the configuration\n",
    "4. Validate that all columns in the dataset match the expected schema\n",
    "\n",
    "The entire process is wrapped in a try-except block to catch and propagate\n",
    "any exceptions that might occur during execution, ensuring proper error handling.\n",
    "\n",
    "Note:\n",
    "- This is the second stage in the ML pipeline, following data ingestion\n",
    "- It ensures data quality and consistency before proceeding to data transformation\n",
    "- The validation results are written to a status file that can be checked by\n",
    "  subsequent pipeline stages to determine if they should proceed\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Initialize configuration\n",
    "    config = ConfigurationManager()\n",
    "    \n",
    "    # Get component-specific configuration with schema information\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    \n",
    "    # Initialize data validation component\n",
    "    data_validation = DataValiadtion(config=data_validation_config)\n",
    "    \n",
    "    # Execute validation of all columns against schema\n",
    "    data_validation.validate_all_columns()\n",
    "    \n",
    "except Exception as e:\n",
    "    # Propagate any exceptions for handling at a higher level\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602b3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
