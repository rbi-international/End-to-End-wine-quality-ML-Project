# config.yaml
# Central configuration file - Modify settings here instead of changing code
# Helps future developers quickly understand project structure

artifacts_root: artifacts

# Data Ingestion Configuration 
# First step in ML pipeline - handles data sourcing and extraction
data_ingestion:
  root_dir: artifacts/data_ingestion # Storage for all ingestion outputs
  source_URL: https://github.com/entbappy/Branching-tutorial/raw/master/winequality-data.zip # Source data location
  local_data_file: artifacts/data_ingestion/data.zip # Downloaded zip location
  unzip_dir: artifacts/data_ingestion # Where extracted data lives


# Data Validation Configuration
# Controls how the ML pipeline validates the ingested data against the schema
data_validation:
  # Directory where all data validation outputs will be stored
  # This includes validation reports and status files
  root_dir: artifacts/data_validation
  
  # Path to the unzipped CSV file that will be validated
  # This is the output from the data ingestion step
  unzip_data_dir: artifacts/data_ingestion/winequality-red.csv
  
  # File where the validation status will be written
  # Contains "True" if validation passed, "False" otherwise
  # This is used by subsequent pipeline stages to determine if they should proceed
  STATUS_FILE: artifacts/data_validation/status.txt


# Data Transformation Configuration
# Controls how the ML pipeline preprocesses and transforms the validated data
data_transformation:
  # Directory where all data transformation outputs will be stored
  # This includes preprocessed datasets, transformation artifacts, and fitted preprocessors
  root_dir: artifacts/data_transformation
  
  # Path to the validated CSV file that will be transformed
  # This is the same file that was validated in the previous pipeline stage
  data_path: artifacts/data_ingestion/winequality-red.csv


# Model Trainer Configuration
# Controls how the ML pipeline trains and evaluates the prediction model
model_trainer:
  # Directory where all model training outputs will be stored
  # This includes the trained model file and any training metrics
  root_dir: artifacts/model_trainer
  
  # Path to the training data created during data transformation
  # This is used to train the machine learning model
  train_data_path: artifacts/data_transformation/train.csv
  
  # Path to the testing data created during data transformation
  # This is used to evaluate the trained model's performance
  test_data_path: artifacts/data_transformation/test.csv
  
  # Filename for saving the trained model
  # The model will be serialized using joblib for easy loading in later stages
  model_name: model.joblib


# Model Evaluation Configuration
# Controls how the ML pipeline evaluates the trained model's performance
model_evaluation:
  # Directory where all model evaluation outputs will be stored
  # This includes performance metrics and evaluation reports
  root_dir: artifacts/model_evaluation
  
  # Path to the testing data created during data transformation
  # This data is used to evaluate the model's performance on unseen examples
  test_data_path: artifacts/data_transformation/test.csv
  
  # Path to the trained model file from the model trainer stage
  # This is the model to be evaluated
  model_path: artifacts/model_trainer/model.joblib
  
  # File where evaluation metrics will be saved in JSON format
  # These metrics typically include RMSE, MAE, RÂ² and can be used for model comparison
  metric_file_name: artifacts/model_evaluation/metrics.json


